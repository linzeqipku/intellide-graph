[
  {
    "name": "abdera",
    "description": "The goal of the Apache Abdera project is to build a functionally-complete, high-performance implementation of the IETF Atom Syndication Format (RFC 4287) and Atom Publishing Protocol (RFC 5023) specifications."
  },
  {
    "name": "Accumulo",
    "description": "Apache Accumulo® is a sorted, distributed key\/value store that provides robust, scalable data storage and retrieval. With Apache Accumulo, users can store and manage large data sets across a cluster. Accumulo uses Apache Hadoop's HDFS to store its data and Apache ZooKeeper for consensus. While many users interact directly with Accumulo, several open source projects use Accumulo as their underlying store."
  },
  {
    "name": "ace",
    "description": "Apache ACE is a software distribution framework that allows you to centrally manage and distribute software components, configuration data and other artifacts to target systems. It is built using OSGi and can be deployed in different topologies. The target systems are usually also OSGi based, but don't have to be."
  },
  {
    "name": "Allura",
    "description": "Apache Allura is an open source implementation of a software forge, a web site that manages source code repositories, bug reports, discussions, wiki pages, blogs, and more for any number of individual projects."
  },
  {
    "name": "Ambari",
    "description": "A completely open source management platform for provisioning, managing, monitoring and securing Apache Hadoop clusters. Apache Ambari takes the guesswork out of operating Hadoop. Apache Ambari, as part of the Hortonworks Data Platform, allows enterprises to plan, install and securely configure HDP making it easier to provide ongoing cluster maintenance and management, no matter the size of the cluster."
  },
  {
    "name": "Ant",
    "description": "Apache Ant is a Java library and command-line tool whose mission is to drive processes described in build files as targets and extension points dependent upon each other. The main known usage of Ant is the build of Java applications. Ant supplies a number of built-in tasks allowing to compile, assemble, test and run Java applications. Ant can also be used effectively to build non Java applications, for instance C or C++ applications. More generally, Ant can be used to pilot any type of process which can be described in terms of targets and tasks. Ant is written in Java. Users of Ant can develop their own \"antlibs\" containing Ant tasks and types, and are offered a large number of ready-made commercial or open-source \"antlibs\". Ant is extremely flexible and does not impose coding conventions or directory layouts to the Java projects which adopt it as a build tool."
  },
  {
    "name": "Any23",
    "description": "Anything To Triples (any23) is a library, a web service and a command line tool that extracts structured data in RDF format from a variety of Web documents. Apache Any23 is written in Java and licensed under the Apache License v2.0. Apache Any23 can be used in various ways:\nAs a library in Java applications that consume structured data from the Web.\nAs a command-line tool for extracting and converting between the supported formats.\nAs online service API available at any23.org."
  },
  {
    "name": "Apex",
    "description": "Apex is a Hadoop YARN native platform that unifies stream and batch processing. It processes big data in-motion in a way that is highly scalable, highly performant, fault tolerant, stateful, secure, distributed, and easily operable. Write your business logic and leave all operability to the platform. It provides a simple API that enables developers to write or re-use generic Java code, thereby lowering the expertise needed to write big data applications. The Apex platform comes with Malhar, a library of operators (units of functionality) that can be leveraged to quickly create non-trivial applications. Includes many connectors for messaging systems, databases, files etc."
  },
  {
    "name": "APR",
    "description": "The mission of the Apache Portable Runtime (APR) project is to create and maintain software libraries that provide a predictable and consistent interface to underlying platform-specific implementations. The primary goal is to provide an API to which software developers may code and be assured of predictable if not identical behaviour regardless of the platform on which their software is built, relieving them of the need to code special-case conditions to work around or take advantage of platform-specific deficiencies or features."
  },
  {
    "name": "Archiva",
    "description": "Apache Archiva™ is an extensible repository management software that helps taking care of your own personal or enterprise-wide build artifact repository. It is the perfect companion for build tools such as Maven, Continuum, and ANT.\nArchiva offers several capabilities, amongst which remote repository proxying, security access management, build artifact storage, delivery, browsing, indexing and usage reporting, extensible scanning functionality… and many more!"
  },
  {
    "name": "Aries",
    "description": "The Aries project consists of a set of pluggable Java components enabling an enterprise OSGi application programming model. This includes implementations (and extensions) of the following Enterprise OSGi specifications:\n\nAsynchronous Services and Promises Specification\nBlueprint Specification\nJTA Transaction Services Specification\nJMX Management Model Specification\nJNDI Services Specification\nJPA Service Specification\nService Loader Mediator Specification\nSubsystem Service Specification\n\nThe specifications are defined in the OSGi Alliance Enterprise Expert Group (EEG) for deployment to a variety of OSGi based runtimes. The OSGi R6 Enterprise Specification can be found here:\nhttp:\/\/www.osgi.org\/Download\/Release6"
  },
  {
    "name": "Arrow",
    "description": "Apache Arrow is a cross-language development platform for in-memory data. It specifies a standardized language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware. It also provides computational libraries and zero-copy streaming messaging and interprocess communication. Languages currently supported include C, C++, Java, JavaScript, Python, and Ruby."
  },
  {
    "name": "AsterixDB",
    "description": "Apache AsterixDB™ is a scalable, open source Big Data Management System (BDMS)."
  },
  {
    "name": "Atlas",
    "description": "Atlas is a scalable and extensible set of core foundational governance services – enabling enterprises to effectively and efficiently meet their compliance requirements within Hadoop and allows integration with the whole enterprise data ecosystem. Apache Atlas provides open metadata management and governance capabilities for organizations to build a catalog of their data assets, classify and govern these assets and provide collaboration capabilities around these data assets for data scientists, analysts and the data governance team."
  },
  {
    "name": "attic",
    "description": "The Apache Attic was created in November 2008 to provide process and solutions to make it clear when an Apache project has reached its end of life. Specifically to be:\"responsible for the oversight of projects which otherwise would not have oversight; and be it further ... is not authorized to actively develop and release the projects under its oversight\""
  },
  {
    "name": "Bahir",
    "description": "Apache Bahir provides extensions to multiple distributed analytic platforms, extending their reach with a diversity of streaming connectors and SQL data sources. Currently, Bahir provides extensions for Apache Spark and Apache Flink."
  },
  {
    "name": "Avro",
    "description": "Apache Avro™ is a data serialization system.\n\nAvro provides:\n\nRich data structures.\nA compact, fast, binary data format.\nA container file, to store persistent data.\nRemote procedure call (RPC).\nSimple integration with dynamic languages. Code generation is not required to read or write data files nor to use or implement RPC protocols. Code generation as an optional optimization, only worth implementing for statically typed languages."
  },
  {
    "name": "Bigtop",
    "description": "Bigtop is an Apache Foundation project for Infrastructure Engineers and Data Scientists looking for comprehensive packaging, testing, and configuration of the leading open source big data components. Bigtop supports a wide range of components\/projects, including, but not limited to, Hadoop, HBase and Spark.\n"
  },
  {
    "name": "Bloodhound",
    "description": "Manage software products. Keep track of features, tasks and bugs. Manage anything from your one pet project to dozens of commercial or open source products, and scale seamlessly in-between. The built-in Wiki allows you to make plans, create proposals and store other information. The full-text search intelligently ranks results to help you find what you're looking for quickly. Or just type in the ticket id to navigate directly to it, and more. New users wil find it easy starting out and learn many powerful features along the way. The dashboard provides an overview of work assigned to you, or watched by you, so you'll never lose track."
  },
  {
    "name": "BookKeeper",
    "description": "A scalable, fault-tolerant, and low-latency storage service optimized for real-time workloads."
  },
  {
    "name": "Brooklyn",
    "description": "Your applications, any clouds, any containers, anywhere. Use Apache brooklyn for modeling, deploying and managing. "
  },
  {
    "name": "Buildr",
    "description": "Apache Buildr is a build system for Java-based applications, including support for Scala, Groovy and a growing number of JVM languages and tools. We wanted something that’s simple and intuitive to use, so we only need to tell it what to do, and it takes care of the rest. But also something we can easily extend for those one-off tasks, with a language that’s a joy to use. And of course, we wanted it to be fast, reliable and have outstanding dependency management.\n\n"
  },
  {
    "name": "BVal",
    "description": "Apache BVal delivers an implementation of the Java Bean Validation Specification which is TCK compliant, works on Java SE 6 or later, and uses the Apache Software License v2.0."
  },
  {
    "name": "Calcite",
    "description": "Apache Calcite is a dynamic data management framework. It contains many of the pieces that comprise a typical database management system, but omits some key functions: storage of data, algorithms to process data, and a repository for storing metadata."
  },
  {
    "name": "Carbondata",
    "description": "Apache CarbonData is an indexed columnar data format for fast analytics on big data platform, e.g. Apache Hadoop, Apache Spark, etc."
  },
  {
    "name": "Cassandra",
    "description": "The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data.Cassandra's support for replicating across multiple datacenters is best-in-class, providing lower latency for your users and the peace of mind of knowing that you can survive regional outages."
  },
  {
    "name": "Cayenne",
    "description": "Cayenne is distributed with CayenneModeler - a complete GUI mapping tool that supports reverse-engineering of RDBMS schemas, editing object-relational mapping projects, generation of Java source code for the persistent objects and other functions."
  },
  {
    "name": "Celix",
    "description": "Apache Celix is an implementation of the OSGi specification adapted to C and C++. It is a provides a framework to develop (dynamic) modular software applications using component and\/or service-oriented programming. Apache Celix is primarily developed in C and adds an additional abstraction, in the form of a library, to support for C++. Modularity in Apache Celix is achieved by supporting - run-time installed - bundles. Bundles are zip files and can contain software modules in the form of shared libraries. Modules can provide and request dynamic services, for and from other modules, by interacting with a provided bundle context. Services in Apache Celix are \"plain old\" structs with function pointers or \"plain old C++ Objects\" (POCO)."
  },
  {
    "name": "Chemistry",
    "description": "Apache Chemistry provides open source implementations of the Content Management Interoperability Services (CMIS) specification."
  },
  {
    "name": "Chukwa",
    "description": "Apache Chukwa is an open source data collection system for monitoring large distributed systems. Apache Chukwa is built on top of the Hadoop Distributed File System (HDFS) and Map\/Reduce framework and inherits Hadoop’s scalability and robustness. Apache Chukwa also includes a ﬂexible and powerful toolkit for displaying, monitoring and analyzing results to make the best use of the collected data."
  },
  {
    "name": "Clerezza",
    "description": "Apache Clerezza is a set of Java libraries for management of semantically linked data. Contents are stored as triples based on W3C RDF specification. Apache Clerezza defines a technology-agnostic layer to access and modify triple stores. It provides a java implementation of the graph data model specified by W3C RDF and functionalities to operate on that data model. Apache Clerezza offers a service interface to access multiple named graphs and it can use various providers to manage RDF graphs in a technology specific manner, e.g., using Jena or Sesame. It also provides for adaptors that allow an application to use various APIs (including the Jena api) to process RDF graphs. Furthermore, Apache Clerezza offers a serialization and a parsing service to convert a graph into a certain representation (format) and vice versa."
  },
  {
    "name": "click",
    "description": "Apache Click™ is a modern JEE web application framework, providing a natural rich client style programming model. Apache Click is designed to be very easy to learn and use, with developers getting up and running within a day."
  },
  {
    "name": "CloudStack",
    "description": "Apache CloudStack is open source software designed to deploy and manage large networks of virtual machines, as a highly available, highly scalable Infrastructure as a Service (IaaS) cloud computing platform. CloudStack is used by a number of service providers to offer public cloud services, and by many companies to provide an on-premises (private) cloud offering, or as part of a hybrid cloud solution."
  },
  {
    "name": "Cocoon",
    "description": "Apache Cocoon is a web development framework built around the concepts of separation of concerns (making sure people can interact and collaborate on a project, without stepping on each other toes) and component-based web development.\nCocoon implements these concepts around the notion of \"component pipelines\", each component on the pipeline specializing on a particular operation. This makes it possible to use a \"building block\" approach for web solutions, hooking together components into pipelines without any required programming.\nCocoon is \"web glue for your web application development needs\". It is a glue that keeps concerns separate and allows parallel evolution of the two sides, improving development pace and reducing the chance of conflicts.\nCocoon has been designed to coexist and interoperate side-by-side with your existing J2EE solutions or to give them new functionality without requiring any change in the existing infrastructure.\nCocoon interacts with many data sources, including filesystems, RDBMS, LDAP, native XML databases, SAP® systems and network-based data sources. It adapts content delivery to the capabilities of different devices like HTML, WML, PDF, SVG, and RTF, to name just a few. You can run Cocoon as a Servlet as well as through a powerful, commandline interface. The deliberate design of its abstract environment gives you the freedom to extend its functionality to meet your special needs in a highly modular fashion."
  },
  {
    "name": "Commons",
    "description": "Apache Commons is an Apache project focused on all aspects of reusable Java components.\nThe Apache Commons project is composed of three parts:\nThe Commons Proper - A repository of reusable Java components.\nThe Commons Sandbox - A workspace for Java component development.\nThe Commons Dormant - A repository of components that are currently inactive.\nYou may also read our charter, which spells out the goals of the project in greater detail.\nThe Apache Commons source code repositories are writable for all ASF committers. While Apache Commons is a Commit-Then-Review community, we would consider it polite and helpful for contributors to announce their intentions and plans on the dev mailing list before committing code. All contributors should read our contributing guidelines. We accept patches as SVN diff files uploaded to the Apache bugtracker or as pull request via our github mirrors."
  },
  {
    "name": "continuum",
    "description": "Apache Continuum moved into the Attic in May 2016. Continuum was an enterprise-ready continuous integration server with features such as automated builds, release management, role-based security, and integration with popular build tools and source control management systems."
  },
  {
    "name": "Cordova",
    "description": "Apache Cordova is an open-source mobile development framework. It allows you to use standard web technologies - HTML5, CSS3, and JavaScript for cross-platform development. Applications execute within wrappers targeted to each platform, and rely on standards-compliant API bindings to access each device's capabilities such as sensors, data, network status, etc.\n\nUse Apache Cordova if you are:\n\na mobile developer and want to extend an application across more than one platform, without having to re-implement it with each platform's language and tool set.\n\na web developer and want to deploy a web app that's packaged for distribution in various app store portals.\n\na mobile developer interested in mixing native application components with a WebView (special browser window) that can access device-level APIs, or if you want to develop a plugin interface between native and WebView components."
  },
  {
    "name": "CouchDB",
    "description": "Apache CouchDB™ lets you access your data where you need it by defining the Couch Replication Protocol that is implemented by a variety of projects and products that span every imaginable computing environment from globally distributed server-clusters, over mobile phones to web browsers. Software that is compatible with the Couch Replication Protocol include: PouchDB, Cloudant, and Couchbase Lite.\n\nStore your data safely, on your own servers, or with any leading cloud provider. Your web- and native applications love CouchDB, because it speaks JSON natively and supports binary for all your data storage needs. The Couch Replication Protocol lets your data flow seamlessly between server clusters to mobile phones and web browsers, enabling a compelling, offline-first user-experience while maintaining high performance and strong reliability. CouchDB comes with a developer-friendly query language, and optionally MapReduce for simple, efficient, and comprehensive data retrieval."
  },
  {
    "name": "Creadur",
    "description": "This project started as just Rat, a release auditing tool good with licenses, coded in Java with plugins for Ant and Maven. After adding some new tricks, it became clear that creating one uber-tool in one language is less useful than collecting a suite:\n\nApache Rat™ audits license headers — the boilerplate text needed in most source files. Coded in Java, it runs from the command line with plugins for Maven and Ant. Download the latest release or read the release notes.\nApache Tentacles™ helps to audit in bulk components uploaded to a staging repository. Coded in Java, it runs from the command line.\nApache Whisker™ assists assembled applications maintain correct legal documentation. Coded in Java, it runs from the command line or as a plugin for Maven."
  },
  {
    "name": "Crunch",
    "description": "Running on top of Hadoop MapReduce and Apache Spark, the Apache Crunch™ library is a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce. The APIs are especially useful when processing data that does not fit naturally into relational model, such as time series, serialized object formats like protocol buffers or Avro records, and HBase rows and columns. For Scala users, there is the Scrunch API, which is built on top of the Java APIs and includes a REPL (read-eval-print loop) for creating MapReduce pipelines."
  },
  {
    "name": "cTAKES",
    "description": "Apache cTAKES™ is a natural language processing system for extraction of information from electronic medical record clinical free-text."
  },
  {
    "name": "Curator",
    "description": "Apache Curator is a Java\/JVM client library for Apache ZooKeeper, a distributed coordination service. It includes a highlevel API framework and utilities to make using Apache ZooKeeper much easier and more reliable. It also includes recipes for common use cases and extensions such as service discovery and a Java 8 asynchronous DSL."
  },
  {
    "name": "CXF",
    "description": "\nApache CXF™ is an open source services framework. CXF helps you build and develop services using frontend programming APIs, like JAX-WS and JAX-RS. These services can speak a variety of protocols such as SOAP, XML\/HTTP, RESTful HTTP, or CORBA and work over a variety of transports such as HTTP, JMS or JBI."
  },
  {
    "name": "DataFu",
    "description": "Apache DataFu Pig is a collection of user-defined functions for working with large scale data in Apache Pig. It has a number of useful functions available."
  },
  {
    "name": "DeltaSpike",
    "description": "Apache DeltaSpike is a collection of portable CDI extensions. These ready-to-use modules enable you to integrate tested API extensions into your Java projects.\n\nDeltaSpike consists of a core module and a number of optional modules for providing additional enterprise functionality to your applications. The modules include features for enhanced security with type-safe control over method invocations, integration with schedulers, injection of CDI objects into validators, a transactional context and scope, and much more. DeltaSpike also provides boot and shutdown control over CDI containers in Java SE applications.\n\nAs a CDI extension, DeltaSpike must be used in conjunction with a CDI implementation and supports both JBoss Weld and Apache OpenWebBeans. DeltaSpike is tested on a range of application servers and CDI-enabled containers including Apache TomEE, JBoss AS, WildFly, Oracle GlassFish, and Jetty.\n\nDeltaSpike provides a number of examples to show you how to use and get the most from this technology."
  },
  {
    "name": "Directory",
    "description": "At the Apache Directory Project, there are two LDAP specific projects. The first is a pure Java LDAP Server called Apache Directory Server (ApacheDS) which has been written and certified by the Open Group for LDAPv3. It was started in reaction to the often brittle code that was too hard to manage: the code was written in C and had preprocessor directives strewn all over it for porting.\n\nThe other LDAP related project is called Apache Directory Studio. It is intended to provide the missing LDAP tooling support in addition to Apache Directory Server specific management utilities.\n\nThe general motives for forming the Apache Directory Project can be summarized with the points below:\n\nAvoid low level compiled language for:\nReducing complexity, and increase productivity\nEnabling portability to other platforms with minimal effort\nAttracting more contributors with most common language (Java)\nDevise a more flexible dynamic server designed for:\nExtension\nProtocol experimentation\nHot plug-ability\nSimplicity\nExperiment with and introduce new integration tier constructs for directories:\nTriggers\nViews\nStored Procedures\nQueues\nProvide the missing tooling critical for:\nLDAP Adoption (general for all LDAP servers)\nIncreasing user comfort with LDAP\nLessening the learning curve for those using LDAP\nStimulate commercial vendors to adopt these new capabilities to remain competitive."
  },
  {
    "name": "DRAT",
    "description": "A distributed parallelized ( Map Reduce) wrapper around APACHE RATTM (Release Audit Tool) that \ngoes far beyond RATTM by leveraging Apache OODTTM to dramatically speed up the process."
  },
  {
    "name": "Drill",
    "description": "Drill is an Apache open-source SQL query engine for Big Data exploration. Drill is designed from the ground up to support high-performance analysis on the semi-structured and rapidly evolving data coming from modern Big Data applications, while still providing the familiarity and ecosystem of ANSI SQL, the industry-standard query language. Drill provides plug-and-play integration with existing Apache Hive and Apache HBase deployments."
  },
  {
    "name": "Eagle",
    "description": "Apache Eagle (called Eagle in the following) is an open source analytics solution for identifying security and performance issues instantly on big data platforms e.g. Hadoop1, Spark2, NoSQL etc. It analyzes data activities, yarn applications, jmx metrics, and daemon logs etc., provides state-of-the-art alert engine to identify security breach, performance issues and shows insights."
  },
  {
    "name": "Empire-db",
    "description": "Apache Empire-db is a relational database abstraction layer and data persistence component that allows developers to take a much more SQL-centric approach in application development than traditional Object-relational mapping frameworks (ORM). By providing a unique type-safe object orientated command API Empire-db allows building highly efficient SQL-statements that take full advantage of all database features while eliminating the need for error-prone string operations and literals. This, togehter with DBMS independent record and metadata managment leads to an unprecedented level of ease-of-use and compile-time-safety."
  },
  {
    "name": "excalibur",
    "description": "What is excalibur?\nExcalibur is an open source software project of The Apache Software Foundation. Our primary product is a lightweight, embeddable Inversion of Controlcontainer named Fortress that is written in java.\n\nInversion of control, also known as the hollywood principle (\"don't call us, we'll call you\"), is a simple but powerful concept. The idea is that we don't \"wire up\" all the pieces that make up an application (the \"components\") by writing lots of this-component-uses-that-one-like-so code, nor do we use some kind of lookup directory (like JNDI, for example) where each component decides what components to interact with itself. Instead, we instruct a smart piece of software, the container, to tell the components how to interact.\n\nFortress (and also its predecessor, \"ECM\") is such a container. It is lightweight, by which we mean that it doesn't need a lot of resources, take a lot of disk or memory, or impose all sorts of demands on its environment. Fortress is also embeddable, by which we mean that you can use fortress inside just about every java environment. More concretely, you can use it as the basis of a large standalone development platform (like the Keel project), at the core of a servlet-based web application (like Cocoon) or even as the basis of a GUI application (like GuiApp).\n\nFortress knows how to manage components that have been developed using a rigid lifecycle contract called Avalon-Framework. In the next upcoming release, fortress will also be able to manage ordinary javabeans, and support for other kinds of Inversion of Control are planned.\n\nBesides providing fortress, excalibur also provides a small library of very useful components. We also distribute some of the libraries used to build fortress (and some other containers) seperately. This selection of libraries is called containerkit."
  },
  {
    "name": "Falcon",
    "description": "Apache Falcon is a feed processing and feed management system aimed at making it easier for end consumers to onboard their feed processing and feed management on hadoop clusters."
  },
  {
    "name": "Felix",
    "description": "\"Apache Flex?? is a highly productive, open source application framework for building and maintaining expressive web applications that deploy consistently on all major browsers, desktops and devices (including smartphones, tablets and tv). It provides a modern, standards-based language and programming model that supports common design patterns suitable for developers from many backgrounds. Flex applications can be deployed to the ubiquitous Adobe?? Flash?? Player in the browser, Adobe?? AIRa?¡é on desktop and mobile or to native Androida?¡é, IOSa?¡é, QNX??, Windows?? or Mac?? applications.\","
  },
  {
    "name": "Fineract",
    "description": "Apache Fineract (\\’fīn-,ә-,rakt\\) is an open source system for core banking as a platform. Fineract provides a reliable, robust, and affordable solution for entrepreneurs, financial institutions, and service providers to offer financial services to the world’s 2 billion underbanked and unbanked."
  },
  {
    "name": "Flex",
    "description": "Flex is a powerful, open source application framework that allows you to easily build mobile applications for iOS, Android™, and BlackBerry® Tablet OS devices, as well as traditional applications for browser and desktop using the same programming model, tool, and codebase. You can use the Flex SDK to create a wide range of highly interactive, expressive applications. For example, a data visualization application built in Flex can pull data from multiple back-end sources and display it visually. Business users can drill down into the data for deeper insight and even change the data and have it automatically updated on the back end. A product configuration application can help customers navigate the process of selecting or customizing products online. And a self-service application can guide customers through an address change or help employees complete an otherwise complicated multi-step benefits enrollment."
  },
  {
    "name": "Flume",
    "description": "Apache Forresta?software is a publishing framework that transforms\\n      input from various sources into a unified presentation in one or more\\n      output formats. The modular and extensible plug-in architecture of\\n      Apache Forrest is based on Apache Cocoon and the relevant industry\\n      standards that separate presentation from content. Forrest can generate\\n      static documents, or be used as a dynamic server, or be deployed by its\\n      automated facility.\\n    \","
  },
  {
    "name": "Fluo",
    "description": "With Apache Fluo, users can set up workflows that execute cross node transactions when data changes. These workflows enable users to continuously join new data into large existing data sets without reprocessing all data. Apache Fluo is built on Apache Accumulo.\n\nTake the Fluo tour if you are interested in learning more. Feel free to contact us if you have questions."
  },
  {
    "name": "Forrest",
    "description": "Apache Forresta? software is a publishing framework that transforms\\n      input from various sources into a unified presentation in one or more\\n      output formats. The modular and extensible plug-in architecture of\\n      Apache Forrest is based on Apache Cocoon and the relevant industry\\n      standards that separate presentation from content. Forrest can generate\\n      static documents, or be used as a dynamic server, or be deployed by its\\n      automated facility.\\n    \","
  },
  {
    "name": "FreeMarker",
    "description": "Apache FreeMarker™ is a template engine: a Java library to generate text output (HTML web pages, e-mails, configuration files, source code, etc.) based on templates and changing data. Templates are written in the FreeMarker Template Language (FTL), which is a simple, specialized language (not a full-blown programming language like PHP). Usually, a general-purpose programming language (like Java) is used to prepare the data (issue database queries, do business calculations). Then, Apache FreeMarker displays that prepared data using templates. In the template you are focusing on how to present the data, and outside the template you are focusing on what data to present."
  },
  {
    "name": "Geode",
    "description": "Providing low latency, high concurrency data management solutions since 2002.\nBuild high-speed, data-intensive applications that elastically meet performance requirements at any scale.\nTake advantage of Apache Geode's unique technology that blends advanced techniques for data replication, partitioning and distributed processing. \nApache Geode provides a database-like consistency model, reliable transaction processing and a shared-nothing architecture to maintain very low latency performance with high concurrency processing."
  },
  {
    "name": "Geronimo",
    "description": "Apache Geronimo is an open source server runtime that integrates the best open source projects to create Java\/OSGi server runtimes that meet the needs of enterprise developers and system administrators."
  },
  {
    "name": "Giraph",
    "description": "Apache Giraph is an iterative graph processing system built for high scalability. For example, it is currently used at Facebook to analyze the social graph formed by users and their connections. Giraph originated as the open-source counterpart to Pregel, the graph processing architecture developed at Google and described in a 2010 paper. Both systems are inspired by the Bulk Synchronous Parallel model of distributed computation introduced by Leslie Valiant. Giraph adds several features beyond the basic Pregel model, including master computation, sharded aggregators, edge-oriented input, out-of-core computation, and more. With a steady development cycle and a growing community of users worldwide, Giraph is a natural choice for unleashing the potential of structured datasets at a massive scale. "
  },
  {
    "name": "Gora",
    "description": "The Apache Gora™ open source framework provides an in-memory data model and persistence for big data. Gora supports persisting to column stores, key value stores, document stores, distributed in-memory key\/value stores, in-memory data grids, in-memory caches, distributed multi-model stores, and hybrid in-memory architectures.\n\nGora also enables analysis of data with extensive Apache Hadoop MapReduce™ and Apache Spark™ support. Gora uses the Apache Software License v2.0. Gora graduated from the Apache Incubator in January 2012 to become a top-level Apache project. "
  },
  {
    "name": "Groovy",
    "description": "Apache Groovy is a powerful, optionally typed and dynamic language, with static-typing and static compilation capabilities, for the Java platform aimed at improving developer productivity thanks to a concise, familiar and easy to learn syntax. It integrates smoothly with any Java program, and immediately delivers to your application powerful features, including scripting capabilities, Domain-Specific Language authoring, runtime and compile-time meta-programming and functional programming."
  },
  {
    "name": "Gump",
    "description": "Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH.\nWe call it clientless because no plugins or client software are required.\nThanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser."
  },
  {
    "name": "Hadoop",
    "description": "The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.\n\nThe Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures."
  },
  {
    "name": "Hama",
    "description": "Apache HamaTM is a framework for Big Data analytics which uses the Bulk Synchronous Parallel (BSP) computing model, which was established in 2012 as a Top-Level Project of The Apache Software Foundation. \n\nIt provides not only pure BSP programming model but also vertex and neuron centric programming models, inspired by Google's Pregel and DistBelief. "
  },
  {
    "name": "HBase",
    "description": "Apache HBase™ is the Hadoop database, a distributed, scalable, big data store.\n\nUse Apache HBase™ when you need random, realtime read\/write access to your Big Data. This project's goal is the hosting of very large tables -- billions of rows X millions of columns -- atop clusters of commodity hardware. Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google's Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS."
  },
  {
    "name": "hc",
    "description": "The Apache HttpComponents™ project is responsible for creating and maintaining a toolset of low level Java components focused on HTTP and associated protocols.\n\nThis project functions under the Apache Software Foundation (http:\/\/www.apache.org), and is part of a larger community of developers and users."
  },
  {
    "name": "Helix",
    "description": "Apache Helix is a generic cluster management framework used for the automatic management of partitioned, replicated and distributed resources hosted on a cluster of nodes. Helix automates reassignment of resources in the face of node failure and recovery, cluster expansion, and reconfiguration.\n\n"
  },
  {
    "name": "Hive",
    "description": "The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive."
  },
  {
    "name": "hivemind",
    "description": "HiveMind is an services and configuration microkernel. Its features are also referred to as Inversion of Control (IoC) Container or Lightweight Container. The adoption of HiveMind in an application ensures the use of certain design principles which improve encapsulation, modularization, testability and reusability"
  },
  {
    "name": "HttpComponents",
    "description": "The Apache HttpComponents™ project is responsible for creating and maintaining a toolset of low level Java components focused on HTTP and associated protocols.\n\nThis project functions under the Apache Software Foundation (http:\/\/www.apache.org), and is part of a larger community of developers and users."
  },
  {
    "name": "httpd",
    "description": "The Apache HTTP Server Project is an effort to develop and maintain an open-source HTTP server for modern operating systems including UNIX and Windows. The goal of this project is to provide a secure, efficient and extensible server that provides HTTP services in sync with the current HTTP standards.\n\nThe Apache HTTP Server (\"httpd\") was launched in 1995 and it has been the most popular web server on the Internet since April 1996. It has celebrated its 20th birthday as a project in February 2015.\n\nThe Apache HTTP Server is a project of The Apache Software Foundation."
  },
  {
    "name": "ibatis",
    "description": "Apache iBATIS moved into the Attic in June 2010. iBATIS was a data mapper framework that made it easier to use a relational database with object-oriented applications. There were both Java and .Net implementations.\n\nThe user mailing list, website, downloads and issue tracker all remain, but are read-only. See the website at http:\/\/ibatis.apache.org for more information on iBATIS.\n\nThe iBATIS committers moved over to MyBatis which is the natural successor to iBATIS.\n\nAs with any project in the Attic - if you should choose to fork iBATIS outside of Apache, please let us know so we can link to your project.\n\nArchived versions of iBATIS may be downloaded from the Apache Archives.\n\nAs mentioned above, one fork that has been created is MyBatis at http:\/\/www.mybatis.org\/."
  },
  {
    "name": "Ignite",
    "description": "Apache Ignite™ is a\nmemory-centric distributed database, caching, and processing platform \nfor transactional, analytical, and streaming workloads,\ndelivering in-memory speeds at petabyte scale"
  },
  {
    "name": "Impala",
    "description": "Apache Impala is the open source, native analytic database\nfor Apache Hadoop. Impala is shipped by Cloudera, MapR, Oracle, and Amazon."
  },
  {
    "name": "incubator",
    "description": "Apache iBATIS moved into the Attic in June 2010. iBATIS was a data mapper framework that made it easier to use a relational database with object-oriented applications. There were both Java and .Net implementations.\n\nThe user mailing list, website, downloads and issue tracker all remain, but are read-only. See the website at http:\/\/ibatis.apache.org for more information on iBATIS.\n\nThe iBATIS committers moved over to MyBatis which is the natural successor to iBATIS.\n\nAs with any project in the Attic - if you should choose to fork iBATIS outside of Apache, please let us know so we can link to your project.\n\nArchived versions of iBATIS may be downloaded from the Apache Archives.\n\nAs mentioned above, one fork that has been created is MyBatis at http:\/\/www.mybatis.org\/."
  },
  {
    "name": "Isis",
    "description": "Apache Isis is a framework for rapidly developing domain-driven apps in Java. Write your business logic in entities, domain services and repositories, and the framework dynamically (at runtime) generates a representation of that domain model as a webapp or as a RESTful API. For prototyping or production.\","
  },
  {
    "name": "jakarta",
    "description": "Founded in 1999, the Jakarta Project housed a diverse set of popular open source Java solutions. In 2005, as a part of creating a flatter Apache Software Foundation, Jakarta subprojects began to become full top-level Apache projects. This process has continued to this day, all subprojects have now left the Jakarta project to become top level projects, join other TLPs (Commons), or in some cases been retired."
  },
  {
    "name": "James",
    "description": "James stands for Java Apache Mail Enterprise Server!\nIt has a modular architecture based on a rich set of modern and efficient components which provides at the end complete, stable, secure and extendable Mail Servers running on the JVM.\n\nCreate your own personal solution of emails treatment by assembling the components you need thanks to the Inversion of Control mail platform offered and go further customizing filtering and routing rules using James Mailet Container."
  },
  {
    "name": "jclouds",
    "description": "Apache jclouds® is an open source library that helps you get started in the cloud and utilizes your Java or Clojure development skills. The jclouds API gives you the freedom to use portable abstractions or cloud-specific features.\n\njclouds tests support of 30 cloud providers and cloud software stacks including Amazon, Azure, GoGrid, OpenStack, Rackspace, and Google. Please see the complete list of jclouds supported providers that are supported by the jclouds API.\n\njclouds offers several API abstractions as Java and Clojure libraries. The most mature of these are BlobStore and ComputeService."
  },
  {
    "name": "JMeter",
    "description": "The Apache JMeter™ application is open source software, a 100% pure Java application designed to load test functional behavior and measure performance. It was originally designed for testing Web Applications but has since expanded to other test functions."
  },
  {
    "name": "Johnzon",
    "description": "Apache Johnzon is a project providing an implementation of JsonProcessing (aka JSR-353) and a set of useful extension for this specification like an Object mapper, some JAX-RS providers and a WebSocket module provides a basic integration with Java WebSocket API (JSR-356)."
  },
  {
    "name": "JSPWiki",
    "description": "\\n        Apache JSPWiki is a feature-rich and extensible WikiWiki engine built around the standard JEE \\n        components (Java, servlets, JSP). It features:\\n        - WikiMarkup\/Structured Text\\n        - File attachments \\n        - Templates support\\n        - Data storage through 3 WikiPage Providers, with the capability to plug new ones\\n        - Security: Authorization and authentication fine grain control\\n        - Easy plugin interface\\n        - UTF-8 support\\n        - JSP-based\\n        - Easy-ish installation\\n        - Page locking to prevent editing conflicts\\n        - Support for Multiple Wikis\\n    ,"
  },
  {
    "name": "jUDDI",
    "description": "Apache Johnzon is a project providing an implementation of JsonProcessing (aka JSR-353) and a set of useful extension for this specification like an Object mapper, some JAX-RS providers and a WebSocket module provides a basic integration with Java WebSocket API (JSR-356)."
  },
  {
    "name": "Juneau",
    "description": "Apache Juneau™ is a single cohesive Java ecosystem consisting of the following parts:\n\njuneau-marshall - A universal toolkit for marshalling POJOs to a wide variety of content types using a common framework with no external library dependencies.\njuneau-dto - A variety of predefined DTOs for serializing and parsing languages such as HTML5, Swagger and ATOM.\njuneau-svl - A simple yet powerful variable replacement language API.\njuneau-config - A sophisticated configuration file API.\njuneau-rest-server - A universal REST server API for creating Swagger-based self-documenting REST interfaces using POJOs, simply deployed as one or more top-level servlets in any Servlet 3.1.0+ container.\njuneau-rest-client - A universal REST client API for interacting with Juneau or 3rd-party REST interfaces using POJOs and proxy interfaces.\njuneau-microservice - A REST microservice API that combines all the features above with a simple configurable Jetty server for creating lightweight standalone REST interfaces that start up in milliseconds.\nQuestions via email to dev@juneau.apache.org are always welcome.\n\nJuneau is packed with features that may not be obvious at first. \nUsers are encouraged to ask for code reviews by providing links to specific source files such as through GitHub. \nNot only can we help you with feedback, but it helps us understand usage patterns to further improve the product."
  },
  {
    "name": "Kafka",
    "description": "Apache Kafka is an open-source stream-processing software platform developed by the Apache Software Foundation, written in Scala and Java. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds."
  },
  {
    "name": "Karaf",
    "description": "Apache Karaf is a modular open source OSGi runtime environment. Apache Karaf can work on top of any of the two most used OSGi frameworks: Apache Felix or Equinox (OSGi), providing additional features."
  },
  {
    "name": "Knox",
    "description": "The Apache Knox Gateway is an Application Gateway for interacting with the REST APIs and UIs of Apache Hadoop deployments. The Knox Gateway provides a single access point for all REST and HTTP interactions with Apache Hadoop clusters."
  },
  {
    "name": "Kudu",
    "description": "A new addition to the open source Apache Hadoop ecosystem, Apache Kudu completes Hadoop's storage layer to enable fast analytics on fast data."
  },
  {
    "name": "Kylin",
    "description": "Apache Kylin™ is an open source Distributed Analytics Engine designed to provide SQL interface and multi-dimensional analysis (OLAP) on Hadoop\/Spark supporting extremely large datasets, original contributed from eBay Inc.\n\nApache Kylin™ lets you query massive data set at sub-second latency in 3 steps.\n\nIdentify a Star\/Snowfalke Schema on Hadoop.\nBuild Cube from the identified tables.\nQuery with ANSI-SQL and get results in sub-second, via ODBC, JDBC or RESTful API."
  },
  {
    "name": "Lens",
    "description": "Apache Kylin™ is an open source Distributed Analytics Engine designed to provide SQL interface and multi-dimensional analysis (OLAP) on Hadoop\/Spark supporting extremely large datasets, original contributed from eBay Inc.\n\nApache Kylin™ lets you query massive data set at sub-second latency in 3 steps.\n\nIdentify a Star\/Snowfalke Schema on Hadoop.\nBuild Cube from the identified tables.\nQuery with ANSI-SQL and get results in sub-second, via ODBC, JDBC or RESTful API."
  },
  {
    "name": "Libcloud",
    "description": "Apache Libcloud is a Python library which hides differences between different cloud provider APIs and allows you to manage different cloud resources through a unified and easy to use API."
  },
  {
    "name": "Logging",
    "description": "When writing a library it is very useful to log information. However there are many logging implementations out there, and a library cannot impose the use of a particular one on the overall application that the library is a part of.\n\nThe Logging package is an ultra-thin bridge between different logging implementations. A library that uses the commons-logging API can be used with any logging implementation at runtime. Commons-logging comes with support for a number of popular logging implementations, and writing adapters for others is a reasonably simple task.\n\nApplications (rather than libraries) may also choose to use commons-logging. While logging-implementation independence is not as important for applications as it is for libraries, using commons-logging does allow the application to change to a different logging implementation without recompiling code.\n\nNote that commons-logging does not attempt to initialise or terminate the underlying logging implementation that is used at runtime; that is the responsibility of the application. However many popular logging implementations do automatically initialise themselves; in this case an application may be able to avoid containing any code that is specific to the logging implementation used."
  },
  {
    "name": "Lucene",
    "description": "Apache Lucene is a free and open-source information retrieval software library, originally written completely in Java by Doug Cutting. Lucene has been ported to other programming languages including Object Pascal, Perl, C#, C++, Python, Ruby and PHP."
  },
  {
    "name": "Lucene.Net",
    "description": "Apache Lucene.Net is a port of the Lucene search engine library, written in C# and targeted at .NET runtime users. The Lucene search library is based on an inverted index."
  },
  {
    "name": "Lucy",
    "description": "The Apache Lucy search engine library provides full-text search for dynamic programming languages. It is a \"loose C\" port of the Apache Lucene™ search engine library for Java."
  },
  {
    "name": "MADlib",
    "description": "In a world of ever increasing data size, many existing analytics solutions are not up to the task. The MADlib project seeks to address this need by creating a framework built to take advantage of modern computing capabilities to provide robust solutions that scale with the needs of the business.\n\nOur approach is to leverage the efforts of commercial practice, academic research, and the open-source development community. Please watch the short video below for more details on the product."
  },
  {
    "name": "Mahout",
    "description": "Apache Mahout is a distributed linear algebra framework and mathematically expressive Scala DSL designed to let mathematicians, statisticians, and data scientists quickly implement their own algorithms. Apache Spark is the recommended out-of-the-box distributed back-end, can be extended to other distributed backends."
  },
  {
    "name": "ManifoldCF",
    "description": "In a world of ever increasing data size, many existing analytics solutions are not up to the task. The MADlib project seeks to address this need by creating a framework built to take advantage of modern computing capabilities to provide robust solutions that scale with the needs of the business.\n\nOur approach is to leverage the efforts of commercial practice, academic research, and the open-source development community. Please watch the short video below for more details on the product."
  },
  {
    "name": "Marmotta",
    "description": "Apache Marmotta is an Open Platform for Linked Data. The goal of Apache Marmotta is to provide an open implementation of a Linked Data Platform that can be used, extended and deployed easily by organizations who want to publish Linked Data or build custom applications on Linked Data."
  },
  {
    "name": "Maven",
    "description": "Apache Maven is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information."
  },
  {
    "name": "Mesos",
    "description": "Apache Mesos is A distributed systems kernel. Mesos is built using the same principles as the Linux kernel, only at a different level of abstraction. The Mesos kernel runs on every machine and provides applications (e.g., Hadoop, Spark, Kafka, Elasticsearch) with API’s for resource management and scheduling across entire datacenter and cloud environments."
  },
  {
    "name": "MetaModel",
    "description": "Apache MetaMode Providing a common interface for discovery, exploration of metadata and querying of different types of data sources"
  },
  {
    "name": "Metron",
    "description": "In a world of ever increasing data size, many existing analytics solutions are not up to the task. The MADlib project seeks to address this need by creating a framework built to take advantage of modern computing capabilities to provide robust solutions that scale with the needs of the business.\n\nOur approach is to leverage the efforts of commercial practice, academic research, and the open-source development community. Please watch the short video below for more details on the product."
  },
  {
    "name": "MINA",
    "description": "Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. It provides an abstract event-driven asynchronous API over various transports such as TCP\/IP and UDP\/IP via Java NIO."
  },
  {
    "name": "Mnemonic",
    "description": "Apache Mnemonic is an advanced hybrid memory storages oriented library, it proposed a non-volatile\/durable Java object model and durable computing service that bring several advantages to significantly improve the performance of massive real-time data processing\/analytics. developers are able to use this library to design their cache-less and SerDe-less high performance applications."
  },
  {
    "name": "mrunit",
    "description": "Apache MRUnit is a Java library that helps developers unit test Apache Hadoop map reduce jobs."
  },
  {
    "name": "MyFaces",
    "description": "Apache MyFaces is a project of the Apache Software Foundation, and hosts several sub-projects relating to the JavaServer™ technology. If you want to know more about how JavaServer™ Faces works, take a look at the MyFaces introduction to JSF"
  },
  {
    "name": "Nifi",
    "description": "Apache NiFi supports powerful and scalable directed graphs of data routing, transformation, and system mediation logic. Some of the high-level capabilities and objectives of Apache NiFi include:\n\nWeb-based user interface\nSeamless experience between design, control, feedback, and monitoring\nHighly configurable\nLoss tolerant vs guaranteed delivery\nLow latency vs high throughput\nDynamic prioritization\nFlow can be modified at runtime\nBack pressure\nData Provenance\nTrack dataflow from beginning to end\nDesigned for extension\nBuild your own processors and more\nEnables rapid development and effective testing\nSecure\nSSL, SSH, HTTPS, encrypted content, etc...\nMulti-tenant authorization and internal authorization\/policy management"
  },
  {
    "name": "ODE",
    "description": "Apache ODE (Orchestration Director Engine) software executes business processes written following the WS-BPEL standard. It talks to web services, sending and receiving messages, handling data manipulation and error recovery as described by your process definition. It supports both long and short living process executions to orchestrate all the services that are part of your application."
  },
  {
    "name": "OFBiz",
    "description": "Apache OFBiz is a suite of business applications flexible enough to be used across any industry. A common architecture allows developers to easily extend or enhance it to create custom features."
  },
  {
    "name": "Olingo",
    "description": "Apache Olingo is a Java library that implements the Open Data Protocol (OData). Apache Olingo serves client and server aspects of OData."
  },
  {
    "name": "oltu",
    "description": "Apache Oltu is an OAuth protocol implementation in Java. It also covers others \"OAuth family\" related implementations such as JWT, JWS and OpenID Connect"
  },
  {
    "name": "onami",
    "description": "Apache Onami is a project focused on the development and maintenance of a set of Google Guice extensions not provided out of the box by the library itself nor the Google developers team, such as integration with 3rd part frameworks or extra functionalities."
  },
  {
    "name": "OODT",
    "description": "Apache Object Oriented Data Technology (OODT) is the smart way to integrate and archive your processes, your data, and its metadata. OODT allows you to: Generate Data, Process Data, Manage Your Data, Distribute Your Data, Analyze Your Data. Allowing for the integration of data, computation, visualization and other components."
  },
  {
    "name": "Oozie",
    "description": "Apache Oozie is a workflow scheduler system to manage Apache Hadoop jobs."
  },
  {
    "name": "Open Climate Workbench",
    "description": "Apache Open Climate Workbench is an effort to develop software that performs climate model evaluation using model outputs from a variety of different sources the Earth System Grid Federation, the Coordinated Regional Climate Downscaling Experiment, the U.S. National Climate Assessment and the North American Regional Climate Change Assessment Program and temporal\/spatial scales with remote sensing data from NASA, NOAA and other agencies. The toolkit includes capabilities for rebinning, metrics computation and visualization."
  },
  {
    "name": "openejb",
    "description": "OpenEJB is an open source, embeddable and lightweight EJB Container System and EJB Server, released under the Apache 2.0 License. OpenEJB has been integrated with Java EE application servers such as Geronimo and WebObjects."
  },
  {
    "name": "OpenJPA",
    "description": "Apache OpenJPA is a Java persistence project at The Apache Software Foundation that can be used as a stand-alone POJO persistence layer or integrated into any Java EE compliant container and many other lightweight frameworks, such as Tomcat and Spring."
  },
  {
    "name": "OpenMeetings",
    "description": "Openmeetings provides video conferencing, instant messaging, white board, collaborative document editing and other groupware tools using API functions of the Red5 Streaming Server for Remoting and Streaming."
  },
  {
    "name": "OpenNLP",
    "description": "The Apache OpenNLP library is a machine learning based toolkit for the processing of natural language text."
  },
  {
    "name": "OpenOffice",
    "description": "Apache OpenOffice is the free and open productivity suite from the Apache Software Foundation."
  },
  {
    "name": "OpenWebBeansopenwebbeans",
    "description": "Apache OpenWebBeans delivers an implementation of the Contexts and Dependency injection for Java EE (CDI) 2.0 Specification (JSR-365). OpenWebBeans is TCK compliant and the latest version works on Java SE 8 or later."
  },
  {
    "name": "ORC",
    "description": "Apache ORC is the smallest, fastest columnar storage for Hadoop workloads."
  },
  {
    "name": "Parquet",
    "description": "Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language."
  },
  {
    "name": "PDFBox",
    "description": "The Apache PDFBox library is an open source Java tool for working with PDF documents. This project allows creation of new PDF documents, manipulation of existing documents and the ability to extract content from documents. Apache PDFBox also includes several command-line utilities. Apache PDFBox is published under the Apache License v2.0."
  },
  {
    "name": "Pig",
    "description": "Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.\n\nAt the present time, Pig's infrastructure layer consists of a compiler that produces sequences of Map-Reduce programs, for which large-scale parallel implementations already exist (e.g., the Hadoop subproject). Pig's language layer currently consists of a textual language called Pig Latin, which has the following key properties:\n\nEase of programming. It is trivial to achieve parallel execution of simple, \"embarrassingly parallel\" data analysis tasks. Complex tasks comprised of multiple interrelated data transformations are explicitly encoded as data flow sequences, making them easy to write, understand, and maintain.\nOptimization opportunities. The way in which tasks are encoded permits the system to optimize their execution automatically, allowing the user to focus on semantics rather than efficiency.\nExtensibility. Users can create their own functions to do special-purpose processing."
  },
  {
    "name": "Pivot",
    "description": "Apache Pivot™ is an open-source platform for building installable Internet applications (IIAs). It combines the enhanced productivity and usability features of a modern user interface toolkit with the robustness of the Java platform."
  },
  {
    "name": "POI",
    "description": "The Apache POI Project's mission is to create and maintain Java APIs for manipulating various file formats based upon the Office Open XML standards (OOXML) and Microsoft's OLE 2 Compound Document format (OLE2). In short, you can read and write MS Excel files using Java. In addition, you can read and write MS Word and MS PowerPoint files using Java. Apache POI is your Java Excel solution (for Excel 97-2008). We have a complete API for porting other OOXML and OLE2 formats and welcome others to participate."
  },
  {
    "name": "Polygene",
    "description": "Apache Polygene™ is a community based effort exploring Composite Oriented Programming for domain centric application development. This includes evolved concepts from Aspect Oriented Programming, Dependency Injection and Domain Driven Design."
  },
  {
    "name": "Predictionio",
    "description": "Apache PredictionIO® is an open source Machine Learning Server built on top of a state-of-the-art open source stack for developers and data scientists to create predictive engines for any machine learning task. It lets you:\n\nquickly build and deploy an engine as a web service on production with customizable templates;\nrespond to dynamic queries in real-time once deployed as a web service;\nevaluate and tune multiple engine variants systematically;\nunify data from multiple platforms in batch or in real-time for comprehensive predictive analytics;\nspeed up machine learning modeling with systematic processes and pre-built evaluation measures;\nsupport machine learning and data processing libraries such as Spark MLLib and OpenNLP;\nimplement your own machine learning models and seamlessly incorporate them into your engine;\nsimplify data infrastructure management.\nApache PredictionIO® can be installed as a full machine learning stack, bundled with Apache Spark, MLlib, HBase, Spray and Elasticsearch, which simplifies and accelerates scalable machine learning infrastructure management."
  },
  {
    "name": "Qpid",
    "description": "Apache Qpid™ makes messaging tools that speak AMQP and support many languages and platforms.\nAMQP is an open internet protocol for reliably sending and receiving messages. It makes it possible for everyone to build a diverse, coherent messaging ecosystem."
  },
  {
    "name": "quetz",
    "description": "Apache Quetzalcoatl moved into the Attic in June 2010. Quetzalcoatl, or Quetz as it was more commonly known, was a project charged with the creation and maintenance of open-source software related to mod_python and the Python programming language. Mainly formed around the mod_python subproject, it didn't have activity in the mod_python community to drive the larger project along."
  },
  {
    "name": "Ranger",
    "description": "Apache Ranger™ is a framework to enable, monitor and manage comprehensive data security across the Hadoop platform.\nThe vision with Ranger is to provide comprehensive security across the Apache Hadoop ecosystem. With the advent of Apache YARN, the Hadoop platform can now support a true data lake architecture. Enterprises can potentially run multiple workloads, in a multi tenant environment. Data security within Hadoop needs to evolve to support multiple use cases for data access, while also providing a framework for central administration of security policies and monitoring of user access."
  },
  {
    "name": "rave",
    "description": "Apache Rave a new web and social mashup engine that aggregates and serves web widgets. Rave is targeted as engine for internet and intranet portals and integrates Apache Shindig & Apache Wookie to provide OpenSocial & W3C widget support, respectively..."
  },
  {
    "name": "REEF",
    "description": "Apache REEF™ (Retainable Evaluator Execution Framework) is a library for developing portable applications for cluster resource managers such as Apache Hadoop™ YARN or Apache Mesos™. Apache REEF drastically simplifies development of those resource managers through the following features:\nCentralized Control Flow: Apache REEF turns the chaos of a distributed application into events in a single machine, the Job Driver. Events include container allocation, Task launch, completion and failure. For failures, Apache REEF makes every effort of making the actual Exception thrown by the Task available to the Driver.\nTask runtime: Apache REEF provides a Task runtime called Evaluator. Evaluators are instantiated in every container of a REEF application. Evaluators can keep data in memory in between Tasks, which enables efficient pipelines on REEF.\nSupport for multiple resource managers: Apache REEF applications are portable to any supported resource manager with minimal effort. Further, new resource managers are easy to support in REEF.\n.NET and Java API: Apache REEF is the only API to write YARN or Mesos applications in .NET. Further, a single REEF application is free to mix and match Tasks written for .NET or Java.\nPlugins: Apache REEF allows for plugins (called “Services”) to augment its feature set without adding bloat to the core. REEF includes many Services, such as a name-based communications between Tasks, MPI-inspired group communications (Broadcast, Reduce, Gather, …) and data ingress."
  },
  {
    "name": "River",
    "description": "River is the implementation of Jini service oriented architecture. It defines a programming model which both exploits and extends Java technology to enable the construction of secure, distributed systems consisting of federations of services and clients. Jini technology can be used to build adaptive network systems that are scalable, evolvable and flexible as typically required in dynamic computing environments."
  },
  {
    "name": "RocketMQ",
    "description": "Apache RocketMQ™ is an open source distributed messaging and streaming data platform."
  },
  {
    "name": "Roller",
    "description": "Apache Roller is a Java-based, full-featured, multi-user and group-blog server suitable for blog sites large and small."
  },
  {
    "name": "Samza",
    "description": "Apache Samza is a distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management."
  },
  {
    "name": "Santuario",
    "description": "The Apache Santuario™ project is aimed at providing implementation of the primary security standards for XML:\nXML-Signature Syntax and Processing\nXML Encryption Syntax and Processing.\nTwo libraries are currently available.\nApache XML Security for Java: This library includes the standard JSR-105 (Java XML Digital Signature) API,  a mature DOM-based implementation of both XML Signature and XML Encryption, as well as a more recent StAX-based (streaming) XML Signature and XML Encryption implementation.\nApache XML Security for C++: This library includes a mature Digital Signature and Encryption implementation using a proprietary C++ API on top of the Xerces-C XML Parser's DOM API. It includes a pluggable cryptographic layer, but support for alternatives to OpenSSL are less complete and less mature."
  },
  {
    "name": "Sentry",
    "description": "Apache Sentry™ is a system for enforcing fine grained role based authorization to data and metadata stored on a Hadoop cluster."
  },
  {
    "name": "Serf",
    "description": "The serf library is a high performance C-based HTTP client library built upon the Apache Portable Runtime (APR) library. It is permissively licensed under the Apache License, v2."
  },
  {
    "name": "ServiceMix",
    "description": "Apache ServiceMix is a flexible, open-source integration container that unifies the features and functionality of Apache ActiveMQ, Camel, CXF, and Karaf into a powerful runtime platform you can use to build your own integrations solutions. It provides a complete, enterprise ready ESB exclusively powered by OSGi."
  },
  {
    "name": "Shiro",
    "description": "Apache Shiro is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. "
  },
  {
    "name": "SIS",
    "description": "Apache Spatial Information System (SIS) is a free software, Java language library for developing geospatial applications. SIS provides data structures for geographic features and associated metadata along with methods to manipulate those data structures. The library is an implementation of GeoAPI 3.0 interfaces and can be used for desktop or server applications."
  },
  {
    "name": "Sling",
    "description": "Apache Sling™ is a framework for RESTful web-applications based on an extensible content tree.\nIn a nutshell, Sling maps HTTP request URLs to content resources based on the request's path, extension and selectors. Using convention over configuration, requests are processed by scripts and servlets, dynamically selected based on the current resource. This fosters meaningful URLs and resource driven request processing, while the modular nature of Sling allows for specialized server instances that include only what is needed.\nSling serves as basis for a variety of applications ranging from blogging engines all the way to enterprise content management systems."
  },
  {
    "name": "Spark",
    "description": "Apache Spark is a unified analytics engine for large-scale data processing."
  },
  {
    "name": "Sqoop",
    "description": "Apache Sqoop is a tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases."
  },
  {
    "name": "Stanbol",
    "description": "Apache Stanbol provides a set of reusable components for semantic content management.\nApache Stanbol's intended use is to extend traditional content management systems with semantic services. Other feasible use cases include: direct usage from web applications (e.g. for tag extraction\/suggestion; or text completion in search fields), 'smart' content workflows or email routing based on extracted entities, topics, etc."
  },
  {
    "name": "stdcxx",
    "description": "The Apache C++ Standard Library project (code name stdcxx, pronounced \"standard C++ library\", not S-T-D-C-X-X) is a collection of algorithms, containers, iterators, and other fundamental components of every piece of software, implemented as C++ classes, templates, and functions essential for writing C++ programs.\nThe goal of the Apache C++ Standard Library is to provide a free implementation of the ISO\/IEC 14882 international standard for C++ that enables source code portability and consistent behavior of programs across all major hardware implementations, operating systems, and compilers, open source and commercial alike. An additional goal is to achieve maximum implementation efficiency on each platform by taking advantage of platform-specific high-performance facilities and features which are often unique to the type of hardware, the operating system or the compiler."
  },
  {
    "name": "Storm",
    "description": "Apache Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!"
  },
  {
    "name": "stratos",
    "description": "Apache Stratos is a highly-extensible Platform-as-a-Service (PaaS) framework that helps run Apache Tomcat, PHP, and MySQL applications and can be extended to support many more environments on all major cloud infrastructures. "
  },
  {
    "name": "Streams",
    "description": "Apache Streams unifies a diverse world of digital profiles and online activities into common formats and vocabularies, and makes these datasets accessible across a variety of databases, devices, and platforms for streaming, browsing, search, sharing, and analytics use-cases."
  },
  {
    "name": "Struts",
    "description": "Apache Struts is a free, open-source, MVC framework for creating elegant, modern Java web applications."
  },
  {
    "name": "Subversion",
    "description": "Apache Subversion is an open source version control system. "
  },
  {
    "name": "Synapse",
    "description": "Apache Synapse is a lightweight and high-performance Enterprise Service Bus (ESB). Powered by a fast and asynchronous mediation engine, Apache Synapse provides exceptional support for XML, Web Services and REST. In addition to XML and SOAP, Apache Synapse supports several other content interchange formats, such as plain text, binary, Hessian and JSON. The wide range of transport adapters available for Synapse, enables it to communicate over many application and transport layer protocols. As of now, Apache Synapse supports HTTP\/S, Mail (POP3, IMAP, SMTP), JMS, TCP, UDP, VFS, SMS, XMPP and FIX."
  },
  {
    "name": "Syncope",
    "description": "Apache Syncope is an Open Source system for managing digital identities in enterprise environments, implemented in Java EE technology and released under Apache 2.0 license."
  },
  {
    "name": "SystemML",
    "description": "Apache SystemML provides an optimal workplace for machine learning using big data. It can be run on top of Apache Spark, where it automatically scales your data, line by line, determining whether your code should be run on the driver or an Apache Spark cluster. Future SystemML developments include additional deep learning with GPU capabilities such as importing and running neural network architectures and pre-trained models for training."
  },
  {
    "name": "Tajo",
    "description": "Apache Tajo is a robust big data relational and distributed data warehouse system for Apache Hadoop. Tajo is designed for low-latency and scalable ad-hoc queries, online aggregation, and ETL (extract-transform-load process) on large-data sets stored on HDFS (Hadoop Distributed File System) and other data sources."
  },
  {
    "name": "Tapestry",
    "description": "Apache Tapestry is A component-oriented framework for creating highly scalable web applications in Java."
  },
  {
    "name": "Tcl",
    "description": "Apache Tcl was born to coordinate and stimulate the development of tools integrating the Tcl programming language with the Apache HTTP web server. Our aim was to combine the power of the Apache web server with the capabilities of the mature, robust and flexible Tcl scripting language."
  },
  {
    "name": "Tez",
    "description": "The Apache TEZ project is aimed at building an application framework which allows for a complex directed-acyclic-graph of tasks for processing data. It is currently built atop Apache Hadoop YARN."
  },
  {
    "name": "Thrift",
    "description": "The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages."
  },
  {
    "name": "Tika",
    "description": "The Apache Tika™ toolkit detects and extracts metadata and text from over a thousand different file types (such as PPT, XLS, and PDF). "
  },
  {
    "name": "Tiles",
    "description": "Tiles allows authors to define page fragments which can be assembled into a complete pages at runtime. These fragments, or tiles, can be used as simple includes in order to reduce the duplication of common page elements or embedded within other tiles to develop a series of reusable templates. These templates streamline the development of a consistent look and feel across an entire application."
  },
  {
    "name": "Tomcat",
    "description": "The Apache Tomcat® software is an open source implementation of the Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket technologies. The Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket specifications are developed under the Java Community Process. The Apache Tomcat software is developed in an open and participatory environment and released under the Apache License version 2. The Apache Tomcat project is intended to be a collaboration of the best-of-breed developers from around the world. We invite you to participate in this open development project. "
  },
  {
    "name": "TomEE",
    "description": "Apache TomEE (pronounced \"Tommy\") is the Java Enterprise Edition of Apache Tomcat (Tomcat + Java EE = TomEE).It’s a Embedded or Remote EE Application Server "
  },
  {
    "name": "Traffic Server",
    "description": "Apache Traffic Server software is a fast, scalable and extensible HTTP\/1.1 and HTTP\/2.0 compliant caching proxy server."
  },
  {
    "name": "Trafodion",
    "description": "Apache Trafodion is a webscale SQL-on-Hadoop solution enabling transactional or operational workloads on Apache Hadoop. \nThe name \"Trafodion\" (the Welsh word for transactions, pronounced \"Tra-vod-eee-on\") was chosen specifically to emphasize the differentiation that Trafodion provides in closing a critical gap in the Hadoop ecosystem. \nTrafodion builds on the scalability, elasticity, and flexibility of Hadoop. Trafodion extends Hadoop to provide guaranteed transactional integrity, enabling new kinds of big data applications to run on Hadoop.\n\n"
  },
  {
    "name": "Turbine",
    "description": "Apache Turbine™ is a servlet based framework that allows experienced Java developers to quickly build web applications. Turbine allows you to use personalize the web sites and to use user logins to restrict access to parts of your application. \nTurbine is a matured and well established framework that is used as the base of many other projects (like e.g. the excellent Jetspeed 1 Portals framework. \nTurbine is an excellent choice for developing applications that make use of a services-oriented architecture. Some of the functionality provided with Turbine includes a security management system (decoupled in Fulcrum Security), a scheduling service, XML-defined form validation server (Fulcrum Intake), and an XML-RPC service for web services. It is a simple task to create new services particular to your application. \nThe Turbine core is free of any dependency on a presentation layer technology. Both JavaServer Pages (JSP) and Velocity are supported inside Turbine. For developers already familiar with JSP, or have existing JSP tag libraries, Turbine offers support for the Sun standard. Velocity is the favorite view technology of most users of the Turbine framework; try it out and see if Velocity can help you develop your web applications faster and work more easily with non-programming designers. \nTurbine is developed in an open, participatory environment and released under the Apache Software License. Turbine is intended to be a collaboration of the best-of-breed developers from around the world. We invite you to participate in this open development project. To learn more about getting involved, look at our \"How to Help\" pages."
  },
  {
    "name": "Twill",
    "description": "Apache Twill is an abstraction over Apache Hadoop® YARN that reduces the complexity of developing distributed applications, allowing developers to focus instead on their application logic. Apache Twill allows you to use YARN’s distributed capabilities with a programming model that is similar to running threads.\nApache Twill dramatically simplifies and reduces development efforts, enabling you to quickly and easily both develop and manage distributed applications through its simple abstraction layer on top of YARN. YARN, although originally designed for MapReduce v2, can be used as a generic cluster resource management framework that can run almost any type of application on a Hadoop® cluster. However, with its powerful capabilities, YARN can introduce complexities for developers.\nIn contrast, Twill’s abstraction model over YARN closely resembles the Java thread model, with which many developers are familiar. Moreover, Twill provides application lifecycle management, service discovery, distributed process coordination, and resiliency to failure, which are required by many distributed applications.\nApache Twill allows you to develop, deploy, and manage your distributed applications with a simpler programming model, with rich built-in features for solving common distributed-application problems. Whether you are a developer or an operating engineer, you will find Apache Twill helps you greatly reduce the effort in developing and operating your applications on a Hadoop® cluster.\n\n"
  },
  {
    "name": "UIMA",
    "description": "Unstructured Information Management applications are software systems that analyze large volumes of unstructured information in order to discover knowledge that is relevant to an end user. An example UIM application might ingest plain text and identify entities, such as persons, places, organizations; or relations, such as works-for or located-at.\nUIMA enables applications to be decomposed into components, for example \"language identification\" => \"language specific segmentation\" => \"sentence boundary detection\" => \"entity detection (person\/place names etc.)\". Each component implements interfaces defined by the framework and provides self-describing metadata via XML descriptor files. The framework manages these components and the data flow between them. Components are written in Java or C++; the data that flows between components is designed for efficient mapping between these languages.\nUIMA additionally provides capabilities to wrap components as network services, and can scale to very large volumes by replicating processing pipelines over a cluster of networked nodes."
  },
  {
    "name": "Usergrid",
    "description": "Usergrid is an open-source Backend-as-a-Service (“BaaS” or “mBaaS”) composed of an integrated distributed NoSQL database, application layer and client tier with SDKs for developers looking to rapidly build web and\/or mobile applications. It provides elementary services (user registration & management, data storage, file storage, queues) and retrieval features (full text search, geolocation search, joins) to power common app features.\nIt is a multi-tenant system designed for deployment to public cloud environments (such as Amazon Web Services, Rackspace, etc.) or to run on traditional server infrastructures so that anyone can run their own private BaaS deployment.\nFor architects and back-end teams, it aims to provide a distributed, easily extendable, operationally predictable and highly scalable solution. For front-end developers, it aims to simplify the development process by enabling them to rapidly build and operate mobile and web applications without requiring backend expertise."
  },
  {
    "name": "VCL",
    "description": "VCL stands for Virtual Computing Lab. It is a free & open-source cloud computing platform with the primary goal of delivering dedicated, custom compute environments to users.\nThe compute environments can range from something as simple as a virtual machine running productivity software to a cluster of powerful physical servers running complex HPC simulations.\nVCL supports provisioning several different types of compute resources including physical bare-metal machines, virtual machines hosted on several different hypervisors, and traditional computing lab computers you would normally find on a university campus.\nThe user interface consists of a self-service web portal. Using the portal, users select from a list of customized environments and make reservations.\nBehind the scenes, the scheduling components built into the web portal determine which compute resources to assign to the reservations. The requested environment is then dynamically provisioned, secured, and configured to allow remote access by the user. The user then remotely connects to the remote compute environment using remote desktop, SSH, or any of the other supported protocols."
  },
  {
    "name": "VXQuery",
    "description": "Apache VXQuery™ will be a standards compliant XML Query processor implemented in Java. The focus is on the evaluation of queries on large amounts of XML data. Specifically the goal is to evaluate queries on large collections of relatively small XML documents. To achieve this queries will be evaluated on a cluster of shared nothing machines."
  },
  {
    "name": "whirr",
    "description": "Apache Whirr is a set of libraries for running cloud services.\nWhirr provides:\n1. A cloud-neutral way to run services. You don't have to worry about the idiosyncrasies of each provider.\n2. A common service API. The details of provisioning are particular to the service.\n3. Smart defaults for services. You can get a properly configured system running quickly, while still being able to override settings as needed.\nYou can also use Whirr as a command line tool for deploying clusters."
  },
  {
    "name": "Wicket",
    "description": "The Apache Wicket project announces the 8th major release of the open source Java web framework servicing websites and applications across the globe for over a decade. With this release Wicket embraces Java 8 idioms fully, allowing the use of lambda expressions in all the right places. With Wicket 8 you can write fewer, faster and more maintainable code."
  },
  {
    "name": "wink",
    "description": "Apache Wink is a simple yet solid framework for building RESTful Web services. It is comprised of a Server module and a Client module for developing and consuming RESTful Web services.\n\nApache Wink Server:\nThe Wink Server module is a complete implementation of the JAX-RS v1.1 specification. On top of this implementation, the Wink Server module provides a set of additional features that were designed to facilitate the development of RESTful Web services.\n\nApache Wink Client:\nThe Wink Client module is a Java based framework that provides functionality for communicating with RESTful Web services. The framework is built on top of the JDK HttpURLConnection and adds essential features that facilitate the development of such client applications."
  },
  {
    "name": "wookie",
    "description": "Apache Wookie is a Java server application that allows you to upload and deploy widgets for your applications; widgets can not only include all the usual kinds of mini-applications, badges, and gadgets, but also fully-collaborative applications such as chats, quizzes, and games.\nWookie is based on the W3C Widgets specification, but widgets can also be included that use extended APIs such as Google Wave Gadgets and OpenSocial."
  },
  {
    "name": "ws",
    "description": "---"
  },
  {
    "name": "Xalan",
    "description": "The Apache Xalan Project develops and maintains libraries and programs that transform XML documents using XSLT standard stylesheets. Our subprojects use the Java and C++ programing languages to implement the XSLT libraries.\nThe Apache Xalan Project was reformed in 2011. It started as a subproject of Apache XML which has since been officially retired. The Apache Xalan Project continues as a top-level project governed by the Apache Software Foundation as a collaborative software development community dedicated to providing robust, full-featured, commercial-quality, and freely available XSLT support on a wide variety of platforms."
  },
  {
    "name": "Xerces",
    "description": "The Apache Xerces Project currently consists of the following sub-projects, each focused on the development of XML parsers and related components in various languages:\n1. Apache Xerces C++ - A processor for parsing, validating, serializing and manipulating XML, written in C++.\n2. Apache Xerces2 Java - A processor for parsing, validating, serializing and manipulating XML, written in Java\n3. Apache Xerces Perl - A processor for parsing, validating, serializing and manipulating XML, written in Perl.\n4. Apache XML Commons - A collection of XML components and utilities, including a catalog resolver and various XML APIs."
  },
  {
    "name": "XML Graphics",
    "description": "The Apache™ XML Graphics Project currently consists of the following sub-projects, each focused on a different aspect of XML Graphics:\n1. Apache Batik - A toolkit for Scalable Vector Graphics (SVG), based in Java.\n2. Apache FOP - A print formatter & renderer for XSL-FO (FO=formatting objects), based in Java.\n3. Apache XML Graphics Commons - A library with various components used by Apache Batik and Apache FOP, written in Java."
  },
  {
    "name": "xml",
    "description": "---"
  },
  {
    "name": "XMLBeans",
    "description": "XMLBeans is a technology for accessing XML by binding it to Java types. XMLBeans provides several ways to get at the XML, including:\n1. Through XML schema that has been compiled to generate Java types that represent schema types. In this way, you can access instances of the schema through JavaBeans-style accessors after the fashion of \"getFoo\" and \"setFoo\". The XMLBeans API also allows you to reflect into the XML schema itself through an XML Schema Object model.\n2. A cursor model through which you can traverse the full XML infoset.\n3. Support for XML DOM."
  },
  {
    "name": "Yetus",
    "description": "Apache Yetus  is a collection of libraries and tools that enable contribution and release processes for software projects. It provides:\n1. a robust system for automatically checking new contributions against a variety of community accepted requirements.\n2. the means to document a well defined supported interface for downstream projects.\n3. tooling to help release managers generate release documentation based on the information provided by community issue trackers and source repositories.\n\nMost of the software is written in shell and scripting languages. In honor of the shell code, the project takes its name Yetus from a synonym of the Cymbium genus of gastropods."
  },
  {
    "name": "Zeppelin",
    "description": "Apache Zeppelin is a Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more."
  },
  {
    "name": "ZooKeeper",
    "description": "ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them ,which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed."
  },
  {
    "name": "TSR-chinese",
    "description": "A program by PKU SEI."
  }
]
